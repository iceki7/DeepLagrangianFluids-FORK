1. torch环境有无
    一键执行失败
    
2.全流程。短途训练+可视化。

3.数据生成
    dpi-net 
    splish


4.数据格式
    zst 
    这个格式是不是作者写过一个接口，既然它能用很多种生成方式得到的话？
        有从numpy转换为zst的接口
    总之要么从zst之前就送入数据。要么绕过zst送入数据。
    绕过更方便。



首先 待学习的数据里 涡度的效果就必须要明显才行 最好是弄些具有代表性的场景
然后学习的时候要把多个场景作为训练数据
（因为一个batch里其实包含了很多个不同的场景，应该是为了方法的泛化）
而每个场景里其实只取了3帧数据。




涡度数据是3维的。学习成本。

简单场景，水块。


数据场景+物理模拟结果。
    our_default_scene。逐帧结果在/partio里
    sim_0002只是表示一个随机种子。它最后会用在train/valid划分中。
    sim0001 和sim0002 连水块形状都不一样



压缩数据的结果。
    our_default_data里。

    sim_xxxx_split 



训练参数：
model_weights.h5

scene.json
train stretegy.yaml

训练：
./train_network_tf.py zxc.yaml
    1.按原网络的方法，在多个场景上训练少量帧，但是造随机场景不方便。顶多也就造3-5个。
    2.在单个场景上随机截取多帧（每一帧都由pos0,pos1,pos2组成）。并迭代1次。
        写一个程序随机截取若干个段（每个段有3帧）。
    就选湍流比较明显的那些帧数里，等间距采样段

    vel0指的是帧在solver中的速度，
    而非帧与帧之间的平均速度（因为帧与帧之间已经历经了多个step）
    
    box和box法向量。box也是粒子。
        1.如果box不是粒子而是平面，就要改网络结构。但这样就会失去泛化性（不规则的边界处理不了了，而且这样的网络能不能用都是个问题）。
        2.造一个和边界差不多大的box盒子出来。

    





训练数据：
    粒子位置，速度，（涡度）
    预测:位置矫正，速度矫正，涡度矫正。
损失函数：
    涡量损失。对于求解出的速度场求涡度。


涡量的直观感受。不要太数学化的。


测试：
    1.给定无湍的模拟（只给一帧进行后续多帧的预测？任给一帧进行修复？）
    2.给定另一个场景

